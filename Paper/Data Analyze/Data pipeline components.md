# 1. Origin

> [!NOTE]
> ## Definition : The start of data in the pipeline
> - different type of data source
> - storage systems

# 2. Destination

> [!NOTE] ## Definition : The data after transfering
> - depends mainly on the practical application of the data

# 3. Dataflow

> [!NOTE] ## Definition : The process of data "flowing" between the starting point and the ending point
> ### ETL
> - Extract : Get data from disparate source systems
> - Transform : Move data into **staging area** and convert data format into a future usable format 
> - Load : load reformatted data to final destination

# 4. Storage

> [!NOTE] ## Definition : The place where data is stored at different stages in the pipeline
> ### depends on many factors(example) : 
> - volume
> - fequency
> - volume of queries to a storage system

# 5. Processing

> [!NOTE] ## Definietion : How to **implement** the process of data changes
> ### Example : 
> - database replication
> - streaming data

# 6. Workflow
>[!NOTE]## Definition : In the pipeline, workflow defines 