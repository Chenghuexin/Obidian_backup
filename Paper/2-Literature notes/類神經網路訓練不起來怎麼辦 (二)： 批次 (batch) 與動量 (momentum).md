---
media: https://www.youtube.com/watch?v=zzbr1h9sF54
---
承上回 : [[類神經網路訓練不起來怎麼辦 (一)： 局部最小值 (local minima) 與鞍點 (saddle point)]] 
# Batch

## Small Batch v.s. Large Batch


- [14:34](https://www.youtube.com/watch?v=zzbr1h9sF54&t=874#t=14:34.01) 用small batch的話，每次更新參數的時候使用的loss function都會是
- [17:50](https://www.youtube.com/watch?v=zzbr1h9sF54&t=1071#t=17:50.98) 
- [20:23](https://www.youtube.com/watch?v=zzbr1h9sF54&t=1223#t=20:23.34) 

# Gradient Descent + Momentum


- [27:25](https://www.youtube.com/watch?v=zzbr1h9sF54&t=1646#t=27:25.71) 考慮了之前移動的方向和gradient的方向來調整參數